<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
	<property>
	  <name>dfs.nameservices</name>
	  <value>hadoop3cluster</value>
	</property>
	<!--命名空间，它的值与fs.defaultFS的值要对应，namenode高可用之后有三个namenode，hadoop3cluster是对外提供的统一入口-->
	<property>
      <name>dfs.permissions.enabled</name>
      <value>false</value>
    </property>
	<!--权限 配置为false-->
	<property>
	  <name>dfs.ha.namenodes.hadoop3cluster</name>
	  <value>nn1,nn2,nn3</value>
	</property>
	<!-- 指定 nameService 是 hadoop3cluster时的nameNode有哪些，这里的值也是逻辑名称，名字随便起，相互不重复即可-->
	<property>
	  <name>dfs.namenode.rpc-address.hadoop3cluster.nn1</name>
	  <value>hadoop3-01:9820</value>
	</property>
	<property>
	  <name>dfs.namenode.rpc-address.hadoop3cluster.nn2</name>
	  <value>hadoop3-02:9820</value>
	</property>
	<property>
	  <name>dfs.namenode.rpc-address.hadoop3cluster.nn3</name>
	  <value>hadoop3-03:9820</value>
	</property>
	<!--所有客户端RPC请求地址-->
	<property>
	  <name>dfs.namenode.http-address.hadoop3cluster.nn1</name>
	  <value>hadoop3-01:9870</value>
	</property>
	<property>
	  <name>dfs.namenode.http-address.hadoop3cluster.nn2</name>
	  <value>hadoop3-02:9870</value>
	</property>
	<property>
	  <name>dfs.namenode.http-address.hadoop3cluster.nn3</name>
	  <value>hadoop3-03:9870</value>
	</property>
	<!--dfs namenode web ui-->
	<property>
      <name>dfs.ha.automatic-failover.enabled</name>
      <value>true</value>
     </property>
	 <!--启动故障自动恢复-->
	<property>
	  <name>dfs.namenode.shared.edits.dir</name>
	  <value>qjournal://hadoop3-01:8485;hadoop3-02:8485;hadoop3-03:8485/hadoop3cluster</value>
	</property>
	<!--指定NameNode的元数据在JournalNode上的存放位置-->
	<property>
	  <name>dfs.journalnode.edits.dir</name>
	  <value>/home/hadoop/data/hadoop3/journaldata/jn</value>
	</property>
	<!-- 指定JournalNode在本地磁盘存放数据的位置 -->
	<property>
	  <name>dfs.client.failover.proxy.provider.hadoop3cluster</name>
	  <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
	</property>
	<!--指定 hadoop3cluster 出故障时，哪个实现类负责执行故障切换-->
	<property>
      <name>dfs.ha.fencing.methods</name>
      <value>sshfence</value>
    </property>
	<!-- 配置隔离机制,shell通过ssh连接active namenode节点，杀掉进程-->
    <property>
      <name>dfs.ha.fencing.ssh.private-key-files</name>
      <value>/home/hadoop/.ssh/id_rsa</value>
    </property>
	<!-- 为了实现SSH登录杀掉进程，还需要配置免密码登录的SSH密匙信息 -->
	<property>
      <name>dfs.ha.fencing.ssh.connect-timeout</name>
      <value>10000</value>
    </property>
    <property>
      <name>dfs.namenode.handler.count</name>
      <value>100</value>
    </property>
	<property>
      <name>dfs.namenode.http.address</name>
      <value>hadoop3-01:50070</value>
    </property>
</configuration>
